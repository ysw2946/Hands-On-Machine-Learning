{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝이란?\n",
    "\n",
    "- 머신러닝은 데이터에서부터 학습하도록 컴퓨터를 프로그래밍하는 과학 또는 예술이다.\n",
    "\n",
    "## 왜 머신러닝을 사용하는가?\n",
    "\n",
    "- 복잡하고 어려운 문제에 전통적인 프로그래밍 기법을 사용하면 시간과 비용이 많이 들고, 유지 보수 또한 힘들어진다.\n",
    "\n",
    "- 반면 머신러닝 기법은 프로그램이 훨씬 짧아지고 유지 보수하기 쉬우며 대부분 정확도 또한 높다.\n",
    "\n",
    "- 또한, 머신러닝 기술을 적용하여 대용량의 데이터를 분석하면 겉으로 보이지 않는 패턴이나 정보를 발견할 수 있는데, 이것을 **데이터마이닝**이라 한다.\n",
    "\n",
    "## 머신러닝 사례\n",
    "\n",
    "- 생산 라인에서 제품 이미지를 분석해 자동으로 분류 : 합성곱신경망(CNN) 을 사용하여 **이미지 분류** 작업\n",
    "- 자동으로 뉴스 기사를 분류 : 순환신경망(RNN), CNN, 트랜스포머를 사용하여 **텍스트 분류(자연어 처리)** 작업\n",
    "- 다양한 성능 지표를 기반으로 회사의 내년도 수익 예측 : 회귀모델을 사용한 **예측** 작업\n",
    "- 음성 명령에 반응하는 앱 만들기 : RNN, CNN, 트랜스포머를 사용한 **음성 인식** 작업\n",
    "- 신용 카드 부정 거래 감지 : **이상치 탐지** 작업\n",
    "- 구매이력을 이용한 고객 분석으로 마케팅 전략 계획 : **군집** 작업\n",
    "- 고차원의 데이터셋을 명확하고 의미있는 그래프로 표현 : **시각화** 작업 \n",
    "\n",
    "## 머신러닝 시스템의 종류\n",
    "\n",
    "- 사람의 감독하에 훈련하는 것인지 아닌지 (**지도, 비지도, 준지도, 강화 학습**)\n",
    "- 실시간으로 점진적인 학습을 하는지 아닌지(**온라인, 배치 학습**)\n",
    "- 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인지 or 데이터셋에서 패턴을 발견하여 예측 모델을 만드는지(**사례 기반, 모델 기반 학습**)\n",
    "\n",
    "### 지도 학습\n",
    "- 알고리즘에 주입하는 훈련 데이터에 레이블이라는 원하는 답이 포함되는 학습 방법\n",
    "- **분류,예측** 등이 있다\n",
    "\n",
    "### 비지도 학습\n",
    "- 알고리즘에 주입하는 훈련 데이터에 레이블이라는 원하는 답이 포함되지 않는 학습 방법\n",
    "- 따라서 데이터에 답이 포함되지 않으므로 시스템이 아무런 도움 없이 학습해야 함\n",
    "- **군집,시각화,특성추출,이상치 및 특이치 탐지, 연관 규칙 학습** 등이 있다\n",
    "\n",
    "### 준지도 학습\n",
    "- 지도 학습과 비지도 학습의 조합으로 이루어져 있는 일부만 답이 있는 데이터를 사용하는 기법\n",
    "\n",
    "### 강화 학습\n",
    "- 학습하는 시스템을 에이전트라고 부르며 **환경을 관찰**해서 **행동을 실행**하고 그 결과로 **보상**을 받는 기법\n",
    "- 가장 큰 보상을 얻기 위해 **정책**이라는 최상의 전략을 스스로 학습\n",
    "- 보행 로봇, 알파고 등이 있다\n",
    "\n",
    "### 배치 학습\n",
    "- 시스템이 점진적으로 학습할 수 없고, **가용한 데이터를 모두 사용**하여 훈련\n",
    "- 시스템을 훈련시키고 제품에 적용하면 더 이상의 학습은 없이 실행. 즉, **학습한 것을 단지 적용만 함**\n",
    "- 머신러닝 시스템을 훈련, 평가, 론칭하는 전체 과정을 쉽게 자동화될 수 있어 배치 학습 시스템에도 변화에 적응할 수 있다.\n",
    "- 하지만 **시간과 자원을 많이 소모**하므로 대용량 데이터 혹은 빠른 데이터 변화에 적응해야 한다면 점진적으로 학습할 수 있는 알고리즘을 사용하는 것이 더 나은 방법\n",
    "\n",
    "### 온라인 학습\n",
    "- 데이터를 순차적으로 한 개씩 또는 미니배치라 부르는 작은 묶음 단위로 주입하여 **점진적으로 시스템을 훈련**\n",
    "- 연속적으로 데이터를 받고 빠른 변화에 스스로 적응하고, 컴퓨팅 자원이 제한된 경우에 적합한 기법\n",
    "\n",
    "### 사례 기반 학습\n",
    "- 시스템이 훈련 샘플을 기억하고, **유사도 측정을 사용해 새로운 데이터와 학습된 샘플을 비교**하는 기법\n",
    "\n",
    "### 모델 기반 학습\n",
    "- 훈련 샘플들의 모델을 만들고 그 모델이 최상의 성능을 내도록 훈련한 후 최적의 파라미터를 구하여 **예측**에 사용하는 기법\n",
    "- 측정 지표로는 모델이 얼마나 좋은지 측정하는 **효용 함수** 또는, 모델이 얼마나 나쁜지 측정하는 **비용 함수**이 있다\n",
    "- 선형 회귀에서 보통 선형 모델의 예측과 훈련 데이터 사이의 **비용함수를 최소화** 하는것이 목표\n",
    "> 1. 데이터 분석\n",
    "> 2. 모델을 선택\n",
    "> 3. 훈련 데이터로 모델 훈련(학습 알고리즘이 비용 함수를 최소화하는 모델 파라미터 찾기)\n",
    "> 4. 새로운 데이터에 모델을 적용 후 예측(이 모델이 잘 일반화되길 기대)\n",
    "\n",
    "## 머신러닝의 주요 도전 과제\n",
    "- 우리가 학습 알고리즘을 선택해서 어떤 데이터에 훈련시키는 것에 대한 문제가 될 수 있는 두가지는 **나쁜 알고리즘과 나쁜 데이터**이다\n",
    "\n",
    "### 충분하지 양의 훈련 데이터\n",
    "- 머신러닝 알고리즘이 잘 작동하려면 아주 간단한 문제라도 매우 많은 양의 데이터가 필요하고, 이미지나 음성 인식 같은 복잡한 문제는 어마어마하게 많은 데이터가 필요할 수 있다\n",
    "\n",
    "### 대표성 없는 훈련 데이터\n",
    "- 일반화가 잘되려면 우리가 일반화하기 원하는 새로운 사례를 훈련 데이터가 잘 대표하는 것이 중요하지만 생각보다 어려운 경우가 많다.\n",
    "- 일반화를 하면서 샘플이 작을때 생기는 **샘플링 잡음** 또는 매우 큰 샘플도 표본 추출 방법이 잘못되서 대표성을 띠지 못하는 **샘플링 편향**등의 문제가 생긴다\n",
    "\n",
    "### 낮은 품질의 데이터\n",
    "- 훈련 데이터에 **에러, 이상치, 잡음** 등으로 가득하다면 머신러닝 시스템이 잘 작동하지 않을 것이다\n",
    "\n",
    "### 관련 없는 특성\n",
    "- 엉터리가 들어가면 엉터리가 나오듯이 훈련 데이터에도 **관련 없는 특성이 적고 관련 있는 특성이 충분**해야 시스템이 학습할 수 있다\n",
    "\n",
    "### 훈련 데이터 과대적합\n",
    "- **과도하게 훈련 데이터를 학습**하게 된다면 과대적합이 나타나는 함정에 빠진다\n",
    "- 과대적합은 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할때 자주 일어난다\n",
    "- 과대적합 해결방법\n",
    "> 1. 파라미터 수가 적은 모델을 선택하거나 훈련 데이터에 있는 특성 수를 줄이거나, 모델에 제약을 가하여 단순화 시킨다\n",
    "> 2. 훈련 데이터를 더 많이 모은다\n",
    "> 3. 훈련 데이터의 잡음을 줄인다\n",
    "- 모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는 것을 **규제**라고 한다\n",
    "- 학습하는 동안 적용할 규제의 양은 **하이퍼 파라미터**가 결정한다.\n",
    "\n",
    "### 훈련 데이터 과소적합\n",
    "- 과대적합과 반대로 **훈련 데이터에 대한 학습이 부족**하여 생기는 문제이다\n",
    "- 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 일어난다\n",
    "- 과소적합 해결방법\n",
    "> 1. 모델 파라미터가 더 많은 강력한 모델을 선택\n",
    "> 2. 학습 알고리즘에 더 좋은 특성을 제공\n",
    "> 3. 모델의 제약을 줄인다(하이퍼 파라미터 감소시킨다)\n",
    "\n",
    "## 테스트와 검증\n",
    "- 일반적으로 훈련, 검증, 테스트 세트를 사용하는 **홀드아웃 방법**을 사용한다\n",
    "- 홀드아웃 검증\n",
    "> 1. 훈련 세트에서 다양한 하이퍼파라미터 값을 가진 여러 모델을 훈련\n",
    "> 2. 검증 세트에서 가장 높은 성능을 내는 모델을 선택\n",
    "> 3. 이 최선의 모델을 전체 훈련 세트에서 다시 훈련하여 최종 모델을 생성\n",
    "> 4. 최종 모델을 테스트 세트에서 평가하여 일반화 오차를 추정\n",
    "\n",
    "- 검증 세트가 너무 작을 경우에 검정 세트 여러개를 사용해 반복적인 **교차 검증**을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
